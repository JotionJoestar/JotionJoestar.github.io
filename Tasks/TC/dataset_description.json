[
	{
		"name": "Yelp-Review",
		"description": "Millions of document level text collected from yelp. There are five classes of dataset. The classes represent the user's rating of the store.",
		"available_transformation_type": ["ut", "ut_ut"],
		"models": [
			{
				"model_name": "BERT_Large+ITPT",
				"paper_link": "https://arxiv.org/abs/1905.05583",
				"github_link": "https://github.com/xuyige/BERT4doc-Classification",
				"paper_name": "How to Fine-Tune BERT for Text Classification?",
				"metric": {
					"Accuracy": 75.8
				}
			},
			{
				"model_name": "LSTM",
				"paper_link": "https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735",
				"github_link": "",
				"paper_name": "Long Short-term Memory",
				"metric": {
					"Accuracy": 73.25
				}
			},
			{
				"model_name": "HLSTM",
				"paper_link": "https://www.aclweb.org/anthology/N16-1174.pdf",
				"github_link": "",
				"paper_name": "Hierarchical Attention Networks for Document Classificatio",
				"metric": {
					"Accuracy": 72.10
				}
			},
			{
				"model_name": "CNN",
				"paper_link": "https://arxiv.org/abs/1408.5882",
				"github_link": "",
				"paper_name": "Convolutional Neural Networks for Sentence Classification",
				"metric": {
					"Accuracy": 62.05
				}
			},
			{
				"model_name": "HCNN",
				"paper_link": "",
				"github_link": "",
				"paper_name": "",
				"metric": {
					"Accuracy": 58.95
				}
			},
			{
				"model_name": "Transformer",
				"paper_link": "https://arxiv.org/abs/1706.03762",
				"github_link": "",
				"paper_name": "Attention Is All You Need",
				"metric": {
					"Accuracy": 66.43
				}
			}

		]
	},
	{
		"name": "IMDB_Large",
		"description": "Millions of movie reviews from IMDB, Choose the most popular reviews from 20 movie categories. There are ten classes of dataset. The classes represent the user's rating of the movie",
		"available_transformation_type": ["ut", "ut_ut"],
		"models": [
			{
				"model_name": "BERT_Large+ITPT",
				"paper_link": "https://arxiv.org/abs/1905.05583",
				"github_link": "https://github.com/xuyige/BERT4doc-Classification",
				"paper_name": "How to Fine-Tune BERT for Text Classification?",
				"metric": {
					"Accuracy": 53.47
				}
			},
			{
				"model_name": "LSTM",
				"paper_link": "https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735",
				"github_link": "",
				"paper_name": "Long Short-term Memory",
				"metric": {
					"Accuracy": 51.53
				}
			},
			{
				"model_name": "HLSTM",
				"paper_link": "https://www.aclweb.org/anthology/N16-1174.pdf",
				"github_link": "",
				"paper_name": "Hierarchical Attention Networks for Document Classificatio",
				"metric": {
					"Accuracy": 47.65
				}
			},
			{
				"model_name": "CNN",
				"paper_link": "https://arxiv.org/abs/1408.5882",
				"github_link": "",
				"paper_name": "Convolutional Neural Networks for Sentence Classification",
				"metric": {
					"Accuracy": 47.83
				}
			},
			{
				"model_name": "HCNN",
				"paper_link": "",
				"github_link": "",
				"paper_name": "",
				"metric": {
					"Accuracy": 43.06
				}
			},
			{
				"model_name": "Transformer",
				"paper_link": "https://arxiv.org/abs/1706.03762",
				"github_link": "",
				"paper_name": "Attention Is All You Need",
				"metric": {
					"Accuracy": 45.33
				}
			}

		]
	},{
		"name": "Amazon-Review",
		"description": "Five million product reviews from Amazon, There are five classes of dataset. The classes represent the user's rating of the product",
		"available_transformation_type": ["ut", "ut_ut"],
		"models": [
			{
				"model_name": "BERT-Large+ITPT",
				"paper_link": "https://arxiv.org/abs/1905.05583",
				"github_link": "https://github.com/xuyige/BERT4doc-Classification",
				"paper_name": "How to Fine-Tune BERT for Text Classification?",
				"metric": {
					"Accuracy": 75.8
				}
			},
			{
				"model_name": "LSTM",
				"paper_link": "https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735",
				"github_link": "",
				"paper_name": "Long Short-term Memory",
				"metric": {
					"Accuracy": 73.25
				}
			},
			{
				"model_name": "HLSTM",
				"paper_link": "https://www.aclweb.org/anthology/N16-1174.pdf",
				"github_link": "",
				"paper_name": "Hierarchical Attention Networks for Document Classificatio",
				"metric": {
					"Accuracy": 72.10
				}
			},
			{
				"model_name": "CNN",
				"paper_link": "https://arxiv.org/abs/1408.5882",
				"github_link": "",
				"paper_name": "Convolutional Neural Networks for Sentence Classification",
				"metric": {
					"Accuracy": 62.05
				}
			},
			{
				"model_name": "HCNN",
				"paper_link": "",
				"github_link": "",
				"paper_name": "",
				"metric": {
					"Accuracy": 58.95
				}
			},
			{
				"model_name": "Transformer",
				"paper_link": "https://arxiv.org/abs/1706.03762",
				"github_link": "",
				"paper_name": "Attention Is All You Need",
				"metric": {
					"Accuracy": 66.43
				}
			}

		]
	},
	{
		"name": "Reuters",
		"description": "Reuters rcv1 and rcv2 800 000 news data, multi label classification, a total of 103 categories",
		"available_transformation_type": ["ut", "ut_ut"],
		"models": [
			{
				"model_name": "BERT_Large+ITPT",
				"paper_link": "https://arxiv.org/abs/1905.05583",
				"github_link": "https://github.com/xuyige/BERT4doc-Classification",
				"paper_name": "How to Fine-Tune BERT for Text Classification?",
				"metric": {
					"Micro-F1": 90.08
				}
			},
			{
				"model_name": "LSTM",
				"paper_link": "https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735",
				"github_link": "",
				"paper_name": "Long Short-term Memory",
				"metric": {
					"Micro-F1": 88.41
				}
			},
			{
				"model_name": "HLSTM",
				"paper_link": "https://www.aclweb.org/anthology/N16-1174.pdf",
				"github_link": "",
				"paper_name": "Hierarchical Attention Networks for Document Classificatio",
				"metric": {
					"Micro-F1": 86.85
				}
			},
			{
				"model_name": "CNN",
				"paper_link": "https://arxiv.org/abs/1408.5882",
				"github_link": "",
				"paper_name": "Convolutional Neural Networks for Sentence Classification",
				"metric": {
					"Micro-F1": 82.49
				}
			},
			{
				"model_name": "HCNN",
				"paper_link": "",
				"github_link": "",
				"paper_name": "",
				"metric": {
					"Micro-F1": 78.32
				}
			},
			{
				"model_name": "Transformer",
				"paper_link": "https://arxiv.org/abs/1706.03762",
				"github_link": "",
				"paper_name": "Attention Is All You Need",
				"metric": {
					"Micro-F1": 86.15
				}
			}

		]
	}

]