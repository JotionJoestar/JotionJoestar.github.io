[
	{
		"name": "SemEval2014-Restaurant",
		"description": "The standard SemEval2014-Restaurant dataset consists of 3,452 training, 150 validation, and 1,120 test English sentences from the restaurant reviews. Our task-specfic transformations are based on SemEval2014-Restaurant-TOWE, which provides opinion words and their position. The test set of SemEval2014-Restaurant-TOWE owns 492 different sentences (847 aspect terms).",
		"available_transformation_type": ["domain", "ut", "domain_domain", "domain_ut", "ut_ut"],
		"dataset_size": 29032,
		"models": [{
				"model_name": "LCF-BERT",
				"paper_link": "https://www.researchgate.net/publication/335238076_LCF_A_Local_Context_Focus_Mechanism_for_Aspect-Based_Sentiment_Classification",
				"github_link": "https://github.com/yangheng95/LC-ABSA",
				"paper_name": "LCF: A Local Context Focus Mechanism for Aspect-Based Sentiment Classification",
				"metric": {
					"Accuracy": 84.82,
					"Macro-F1": 76.99
				}
			},
			{
				"model_name": "BERT+ASPECT",
				"paper_link": "https://www.aclweb.org/anthology/N19-1423/",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/bert_spc.py",
				"paper_name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
				"metric": {
					"Accuracy": 85.18,
					"Macro-F1": 77.43
				}
			},
						{
				"model_name": "BERT-BASE",
				"paper_link": "https://www.aclweb.org/anthology/N19-1423/",
				"github_link": "https://github.com/xuyige/BERT4doc-Classification",
				"paper_name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
				"metric": {
					"Accuracy": 79.02,
					"Macro-F1": 69.17
				}
			},
						{
				"model_name": "MGAN",
				"paper_link": "https://www.aclweb.org/anthology/D18-1380/",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/mgan.py",
				"paper_name": "Multi-grained Attention Network for Aspect-Level Sentiment Classification",
				"metric": {
					"Accuracy": 79.11,
					"Macro-F1": 67.23
				}
			},
						{
				"model_name": "TNet",
				"paper_link": "https://arxiv.org/pdf/1805.01086",
				"github_link": "https://github.com/lixin4ever/TNet",
				"paper_name": "Transformation Networks for Target-Oriented Sentiment Classification",
				"metric": {
					"Accuracy": 78.93,
					"Macro-F1": 67.20
				}
			},
						{
				"model_name": "IAN",
				"paper_link": "https://arxiv.org/pdf/1709.00893",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/ian.py",
				"paper_name": "Interactive Attention Networks for Aspect-Level Sentiment Classification",
				"metric": {
					"Accuracy": 76.43,
					"Macro-F1": 63.78
				}
			},
						{
				"model_name": "MemNet",
				"paper_link": "https://arxiv.org/pdf/1605.08900",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/memnet.py",
				"paper_name": "Aspect Level Sentiment Classification with Deep Memory Network",
				"metric": {
					"Accuracy": 75.71,
					"Macro-F1": 62.23
				}
			},
						{
				"model_name": "ATAE-LSTM",
				"paper_link": "https://www.aclweb.org/anthology/D16-1058/",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/atae_lstm.py",
				"paper_name": "Attention-based lstm for aspect-level sentiment classification",
				"metric": {
					"Accuracy": 77.41,
					"Macro-F1": 63.28
				}
			},
						{
				"model_name": "TD-LSTM",
				"paper_link": "https://arxiv.org/pdf/1512.01100",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/td_lstm.py",
				"paper_name": "Effective LSTMs for Target-Dependent Sentiment Classification",
				"metric": {
					"Accuracy": 77.59,
					"Macro-F1": 63.28
				}
			},
									{
				"model_name": "LSTM",
				"paper_link": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/lstm.py",
				"paper_name": "Long short-term memory",
				"metric": {
					"Accuracy": 76.34,
					"Macro-F1": 63.66
				}
			}
		]
	},
	{
		"name": "SemEval2014-Laptop",
		"description": "The SemEval2014-Laptop dataset consists of 2,163 training, 150 validation, and 638 test English sentences extracted from customer reviews of laptops. Our task-specfic transformations are based on SemEval2014-Laptop-TOWE, which provides opinion words and their position. The test set of SemEval2014-Laptop-TOWE owns 331 different sentences (446 aspect terms).",
		"available_transformation_type": ["domain", "ut", "domain_domain", "domain_ut", "ut_ut"],
		"dataset_size": 638,
		"models": [{
				"model_name": "LCF-BERT",
				"paper_link": "https://www.researchgate.net/publication/335238076_LCF_A_Local_Context_Focus_Mechanism_for_Aspect-Based_Sentiment_Classification",
				"github_link": "https://github.com/yangheng95/LC-ABSA",
				"paper_name": "LCF: A Local Context Focus Mechanism for Aspect-Based Sentiment Classification",
				"metric": {
					"Accuracy": 80.72,
					"Macro-F1": 77.50
				}
			},
			{
				"model_name": "BERT+ASPECT",
				"paper_link": "https://www.aclweb.org/anthology/N19-1423/",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/bert_spc.py",
				"paper_name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
				"metric": {
					"Accuracy": 76.02,
					"Macro-F1": 71.03
				}
			},
						{
				"model_name": "BERT-BASE",
				"paper_link": "https://www.aclweb.org/anthology/N19-1423/",
				"github_link": "https://github.com/xuyige/BERT4doc-Classification",
				"paper_name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
				"metric": {
					"Accuracy": 78.21,
					"Macro-F1": 73.16
				}
			},
						{
				"model_name": "MGAN",
				"paper_link": "https://www.aclweb.org/anthology/D18-1380/",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/mgan.py",
				"paper_name": "Multi-grained Attention Network for Aspect-Level Sentiment Classification",
				"metric": {
					"Accuracy": 72.41,
					"Macro-F1": 65.62
				}
			},
						{
				"model_name": "TNet",
				"paper_link": "https://arxiv.org/pdf/1805.01086",
				"github_link": "https://github.com/lixin4ever/TNet",
				"paper_name": "Transformation Networks for Target-Oriented Sentiment Classification",
				"metric": {
					"Accuracy": 71.16,
					"Macro-F1": 65.90
				}
			},
						{
				"model_name": "IAN",
				"paper_link": "https://arxiv.org/pdf/1709.00893",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/ian.py",
				"paper_name": "Interactive Attention Networks for Aspect-Level Sentiment Classification",
				"metric": {
					"Accuracy": 70.53,
					"Macro-F1": 63.48
				}
			},
						{
				"model_name": "MemNet",
				"paper_link": "https://arxiv.org/pdf/1605.08900",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/memnet.py",
				"paper_name": "Aspect Level Sentiment Classification with Deep Memory Network",
				"metric": {
					"Accuracy": 64.11,
					"Macro-F1": 55.87
				}
			},
						{
				"model_name": "ATAE-LSTM",
				"paper_link": "https://www.aclweb.org/anthology/D16-1058/",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/atae_lstm.py",
				"paper_name": "Attention-based lstm for aspect-level sentiment classification",
				"metric": {
					"Accuracy": 69.91,
					"Macro-F1": 64.08
				}
			},
						{
				"model_name": "TD-LSTM",
				"paper_link": "https://arxiv.org/pdf/1512.01100",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/td_lstm.py",
				"paper_name": "Effective LSTMs for Target-Dependent Sentiment Classification",
				"metric": {
					"Accuracy": 68.34,
					"Macro-F1": 63.22
				}
			},
									{
				"model_name": "LSTM",
				"paper_link": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory",
				"github_link": "https://github.com/songyouwei/ABSA-PyTorch/blob/master/models/lstm.py",
				"paper_name": "Long short-term memory",
				"metric": {
					"Accuracy": 70.38,
					"Macro-F1": 62.59
				}
			}
		]
			
	}

]
